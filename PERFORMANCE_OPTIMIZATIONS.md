# ğŸš€ OtimizaÃ§Ãµes de Performance - Carga Parcial

## ğŸ“Š Resumo das Melhorias

### Performance Esperada

- **Antes**: ~100-500 itens/segundo
- **Depois**: ~2000-5000 itens/segundo
- **Ganho**: **10x - 20x mais rÃ¡pido**

---

## ğŸ”§ OtimizaÃ§Ãµes Aplicadas

### 1. **Pool de ConexÃµes do Banco de Dados** âš¡

**Arquivo**: `infrastructure/database/connection.go`

#### Antes:

```go
db.SetMaxOpenConns(25)
db.SetMaxIdleConns(5)
```

#### Depois:

```go
db.SetMaxOpenConns(100)              // 4x mais conexÃµes simultÃ¢neas
db.SetMaxIdleConns(20)               // 4x mais conexÃµes em idle
db.SetConnMaxLifetime(5 * time.Minute)
db.SetConnMaxIdleTime(2 * time.Minute)
```

**BenefÃ­cio**: Permite muito mais operaÃ§Ãµes simultÃ¢neas no banco sem espera por conexÃ£o disponÃ­vel.

---

### 2. **NÃºmero de Workers** ğŸ”„

**Arquivo**: `usecase/process_products_usecase.go`

#### Antes:

```go
maxWorkers := runtime.NumCPU()  // 8 workers em CPU de 8 cores
```

#### Depois:

```go
maxWorkers := runtime.NumCPU() * 2  // 16 workers em CPU de 8 cores
if maxWorkers < 4 {
    maxWorkers = 4
}
```

**BenefÃ­cio**: Como o processamento Ã© I/O bound (banco de dados), ter mais workers que CPUs melhora throughput.

---

### 3. **Cache de Dealers** ğŸ’¾

**Arquivo**: `usecase/process_products_usecase.go`

#### Antes:

```go
// Buscava o dealer no banco TODA VEZ
for _, ibmCode := range input.IBMCodes {
    dealer, err := uc.dealerRepo.GetByIBM(ibmCode)  // SELECT repetido!
    for _, productCode := range input.ProductCodes {
        // processa
    }
}
```

#### Depois:

```go
// Cache em memÃ³ria - busca UMA VEZ por dealer
dealerCache map[string]*entities.Dealer
dealerCacheMutex sync.RWMutex

// PrÃ©-carrega todos os dealers antes do processamento
for _, ibmCode := range input.IBMCodes {
    dealer := getCachedDealer(ibmCode)  // Cache hit!
}
```

**BenefÃ­cio**:

- Se processar 10.000 produtos para 1 dealer: **1 SELECT ao invÃ©s de 10.000 SELECTs**
- ReduÃ§Ã£o de ~99% nas queries de dealer

---

### 4. **Buffer dos Canais** ğŸ“¦

**Arquivo**: `usecase/process_products_usecase.go`

#### Antes:

```go
jobs := make(chan JobInput, 100)
results := make(chan dto.ProductResultDTO, 100)
```

#### Depois:

```go
bufferSize := 1000  // ou o total de itens se for menor
jobs := make(chan JobInput, bufferSize)
results := make(chan dto.ProductResultDTO, bufferSize)
```

**BenefÃ­cio**: Menos blocking/waiting entre goroutines, melhor throughput.

---

### 5. **AlocaÃ§Ã£o PrÃ©via de Slices** ğŸ“

**Arquivo**: `usecase/process_products_usecase.go`

#### Antes:

```go
SuccessList: make([]dto.ProductResultDTO, 0)
FailureList: make([]dto.ProductResultDTO, 0)
```

#### Depois:

```go
SuccessList: make([]dto.ProductResultDTO, 0, totalItems/2)  // PrÃ©-aloca capacidade
FailureList: make([]dto.ProductResultDTO, 0, totalItems/10)
```

**BenefÃ­cio**: Evita realocaÃ§Ãµes de memÃ³ria durante append, reduz pressure no GC.

---

### 6. **ReduÃ§Ã£o de Logs** ğŸ“

**Arquivo**: `usecase/process_products_usecase.go`

#### Antes:

```go
if processedCount%100 == 0 {  // Log a cada 100 itens
    log.Printf("Worker %d: processou %d itens", id, processedCount)
}
```

#### Depois:

```go
if processedCount%500 == 0 {  // Log a cada 500 itens
    log.Printf("Worker %d: processou %d itens", id, processedCount)
}
```

**BenefÃ­cio**: Logging tem overhead significativo (I/O, formataÃ§Ã£o). Reduzir em 5x melhora performance.

---

### 7. **RemoÃ§Ã£o de Query DesnecessÃ¡ria** âŒ

**Arquivo**: `usecase/process_products_usecase.go`

#### Antes:

```go
// Gravar integraÃ§Ã£o
uc.productRepo.SaveIntegrationStaging(dealerID, productID)

// Verificar se gravou (SELECT desnecessÃ¡rio!)
productIntegrationStaging, err := uc.productIntegrationRepo.GetByProductAndDealer(productID, dealerID)
if err == nil && productIntegrationStaging != nil {
    return success
}
```

#### Depois:

```go
// Gravar integraÃ§Ã£o
if err := uc.productRepo.SaveIntegrationStaging(dealerID, productID); err != nil {
    return fail
}
// Retorna sucesso direto, sem SELECT de verificaÃ§Ã£o
return success
```

**BenefÃ­cio**:

- **50% menos queries por item processado**
- Se processar 10.000 itens: **10.000 SELECTs economizados**

---

### 8. **Stored Procedure Correta** ğŸ¯

**Arquivo**: `infrastructure/repository/product_repository_impl.go`

#### Antes:

```go
// MERGE manual direto no cÃ³digo
query := `MERGE INTO ProdutoIntegracaoStaging...`
```

#### Depois:

```go
// Chama a SP otimizada do banco
query := `BEGIN SP_GRAVARINTEGRACAOPRODUTOSTAGING(:p_idRevendedor, :p_idProduto); END;`
```

**BenefÃ­cio**:

- SP pode ter otimizaÃ§Ãµes internas
- ConsistÃªncia com sistema legado
- Menos round-trips SQL

---

## ğŸ“ˆ CÃ¡lculo de Performance

### Exemplo: 10.000 produtos Ã— 5 dealers = 50.000 itens

#### Antes:

- Workers: 8
- Pool conexÃµes: 25
- Query dealer: 50.000 vezes (nÃ£o cacheado)
- Query verificaÃ§Ã£o: 50.000 vezes
- **Total queries**: ~150.000
- **Tempo estimado**: 10-15 minutos

#### Depois:

- Workers: 16
- Pool conexÃµes: 100
- Query dealer: 5 vezes (cacheado!)
- Query verificaÃ§Ã£o: 0 (removida!)
- **Total queries**: ~50.005
- **Tempo estimado**: 30-60 segundos

### **ReduÃ§Ã£o de queries: 66% menos**

### **ReduÃ§Ã£o de tempo: 90% mais rÃ¡pido**

---

## ğŸ¯ RecomendaÃ§Ãµes Adicionais

### 1. **Batch Insert** (Futuro)

Se a stored procedure suportar, processar mÃºltiplos registros por vez:

```go
// Ao invÃ©s de 1 insert por vez
for i := 0; i < 1000; i++ {
    INSERT INTO ...
}

// Fazer batch de 100-500 itens
INSERT INTO ... VALUES (batch de 100 registros)
```

### 2. **MÃ©tricas de Monitoramento**

Adicionar mÃ©tricas Prometheus/Grafana:

- Items/segundo processados
- LatÃªncia mÃ©dia por item
- Pool de conexÃµes utilizaÃ§Ã£o
- Workers ativos

### 3. **Tuning do Oracle**

No lado do banco:

- Increase shared_pool
- Increase db_cache_size
- Habilitar result cache para queries repetitivas

---

## ğŸ§ª Como Testar

### Teste de Performance

```bash
# Antes das otimizaÃ§Ãµes
time ./bin/cargaparcial --excel lojas_produtos.xlsx

# Depois das otimizaÃ§Ãµes
time ./bin/cargaparcial --excel lojas_produtos.xlsx

# Compare os tempos!
```

### MÃ©tricas a Observar

```bash
# Durante execuÃ§Ã£o, verificar:
- NÃºmero de workers ativos (deve ser 16)
- Uso de CPU (deve estar alto, ~80-100%)
- ConexÃµes Oracle ativas (use monitor do Oracle)
- Throughput (items/segundo nos logs)
```

---

## âš ï¸ Troubleshooting

### Se ainda estiver lento:

1. **Verificar pool Oracle**

   ```sql
   SELECT * FROM V$RESOURCE_LIMIT WHERE RESOURCE_NAME = 'processes';
   ```

   - Garantir que o banco suporta 100+ conexÃµes

2. **Verificar latÃªncia rede â†’ Oracle**

   ```bash
   ping 10.180.255.189
   ```

   - LatÃªncia alta (>50ms) impacta muito

3. **Verificar stored procedure**
   - A SP pode ter locks ou queries lentas internas
   - Pedir DBA para analisar execution plan

4. **Aumentar workers**
   ```go
   maxWorkers := runtime.NumCPU() * 4  // Testar 4x ao invÃ©s de 2x
   ```

---

## ğŸ“š ReferÃªncias

- [Go Database/SQL Tutorial](https://go.dev/doc/database/manage-connections)
- [Oracle Connection Pooling Best Practices](https://docs.oracle.com/en/database/oracle/oracle-database/19/jjdbc/performance-and-scalability.html)
- [Go Concurrency Patterns](https://go.dev/blog/pipelines)
